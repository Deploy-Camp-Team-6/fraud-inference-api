# Fraud Inference API

A production-ready FastAPI service for serving MLflow models for fraud detection. This service is designed for high-availability, observability, and consistency between training and serving environments.

## Features

- **MLflow Integration**: Loads models directly from an MLflow Model Registry.
- **Dynamic Model Selection**: Automatically selects the best model version based on aliases (`champion`) or stages (`Production` > `Staging`).
- **Dependency Validation**: Fails at startup if the serving environment's dependencies (`scikit-learn`, `xgboost`, etc.) are incompatible with the model's training dependencies.
- **High-Performance API**: Built with FastAPI for asynchronous, high-throughput inference.
- **Observability**:
  - Structured JSON logging with `structlog`.
  - Prometheus metrics for requests, latency, model loads, and more.
  - Request ID tracing via `X-Request-ID` header.
- **Atomic Model Refresh**: Hot-swap models via a protected `/admin/refresh-models` endpoint without downtime.
- **Containerized**: Ships with a multi-stage `Dockerfile` and `docker-compose` files for development and deployment.

## Getting Started

### Local Development with Poetry

1.  **Prerequisites**:
    - Python 3.11+
    - Poetry

2.  **Installation**:
    ```bash
    # Install dependencies
    poetry install
    ```

3.  **Environment Variables**:
    Create a `.env` file in the project root. You can copy the development template:
    ```bash
    cp .env.dev .env
    ```
    Edit the `.env` file to set your `MLFLOW_TRACKING_URI` and other necessary variables.

4.  **Run the Service**:
    ```bash
    poetry run uvicorn app.main:app --reload
    ```
    The API will be available at `http://localhost:8000`.

### Local Development with Docker

1.  **Prerequisites**:
    - Docker
    - Docker Compose

2.  **Build and Run**:
    ```bash
    docker-compose -f docker-compose.dev.yml up --build
    ```
    The API will be available at `http://localhost:8000`. The service will hot-reload when you make changes to the `app/` directory.

## API Documentation

API documentation is automatically generated by FastAPI and is available at:
- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

### Endpoints

- `POST /v1/predict`: Performs inference.
- `GET /v1/version`: Returns service and loaded model versions.
- `GET /livez`: Liveness probe.
- `GET /readyz`: Readiness probe (returns 200 OK only when models are loaded).
- `POST /admin/refresh-models`: (Protected) Triggers a hot-swap of all models.
- `GET /metrics`: Exposes Prometheus metrics.

#### Example: Prediction Request (Batch)

```bash
curl -X 'POST' \
  'http://localhost:8000/v1/predict' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "model": "lightgbm",
  "instances": [
    {"feature1": 0.5, "feature2": 1.2},
    {"feature1": 0.8, "feature2": 0.9}
  ]
}'
```

#### Example: Admin Refresh Request

```bash
curl -X 'POST' \
  'http://localhost:8000/v1/admin/refresh-models' \
  -H 'accept: application/json' \
  -H 'X-API-Key: your-secret-api-key'
```

## Configuration

The service is configured via environment variables. See `app/core/config.py` for a full list of available variables. Key variables include:

- `MLFLOW_TRACKING_URI`: **Required**. The URI of your MLflow tracking server.
- `API_KEYS`: Comma-separated list of valid API keys for admin endpoints.
- `LOG_LEVEL`: `debug`, `info`, `warning`, `error`.
- `WORKERS`: Number of uvicorn worker processes.
- `CORS_ORIGINS`: Comma-separated list of allowed CORS origins.

## Deployment

This service is designed to be deployed as a containerized application, for example, on a Docker Swarm cluster.

A sample `deploy/stack.yml` is provided for deployment with Docker Swarm and Traefik as a reverse proxy.

1.  **Build and Push Image**:
    Build the Docker image and push it to a container registry (e.g., GHCR, Docker Hub).
    ```bash
    docker build -t your-registry/fraud-inference-api:latest .
    docker push your-registry/fraud-inference-api:latest
    ```

2.  **Prepare Environment**:
    - Ensure your Docker Swarm is running and connected.
    - Configure secrets for sensitive environment variables like `API_KEYS` and cloud credentials.
    - Update `deploy/stack.yml` with your actual image name, domain names, and secret names.

3.  **Deploy Stack**:
    ```bash
    docker stack deploy -c deploy/stack.yml fraud-api-stack
    ```