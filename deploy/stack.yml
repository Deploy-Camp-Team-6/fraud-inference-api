version: '3.8'

services:
  inference-api:
    image: ${IMAGE_NAME}
    environment:
      MLFLOW_TRACKING_URI: "${MLFLOW_TRACKING_URI}"
      MLFLOW_TRACKING_USERNAME: "${MLFLOW_TRACKING_USERNAME}"
      MLFLOW_TRACKING_PASSWORD: "${MLFLOW_TRACKING_PASSWORD}"
      MLFLOW_S3_ENDPOINT_URL: "${MLFLOW_S3_ENDPOINT_URL}"
      AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID}"
      AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY}"
      LOG_LEVEL: "${LOG_LEVEL:-info}"
      WORKERS: "${WORKERS:-4}"
    networks:
      - traefik-public
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        order: stop-first
      restart_policy:
        condition: on-failure
      labels:
        - traefik.enable=true
        - traefik.docker.network=traefik-public
        - traefik.http.services.inference-api.loadbalancer.server.port=8000
        - traefik.http.routers.inference-api.rule=Host(`${DOMAIN}`)
        - traefik.http.routers.inference-api.entrypoints=websecure
        - traefik.http.routers.inference-api.tls=true
        - traefik.http.routers.inference-api.tls.certresolver=leresolver

networks:
  traefik-public:
    external: true
